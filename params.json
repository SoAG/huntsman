{"name":"Huntsman","tagline":"A simple web spider","body":"\r\n### Install\r\n\r\n```bash\r\nnpm install huntsman --save\r\n```\r\n\r\n[![NPM](https://nodei.co/npm/huntsman.png?downloads=true&stars=true)](https://nodei.co/npm/huntsman/)\r\n\r\n### Example Script\r\n\r\n```javascript\r\n/** Crawl wikipedia and use jquery syntax to extract information from the page **/\r\n\r\nvar huntsman = require('huntsman');\r\nvar spider = huntsman.spider();\r\n\r\nspider.extensions = [\r\n  huntsman.extension( 'recurse' ), // load recurse extension & follow anchor links\r\n  huntsman.extension( 'cheerio' ) // load cheerio extension\r\n];\r\n\r\n// follow pages which match this uri regex\r\nspider.on( /http:\\/\\/en\\.wikipedia\\.org\\/wiki\\/\\w+:\\w+$/, function ( err, res ){\r\n\r\n  // use jquery-style selectors & functions\r\n  var $ = res.extension.cheerio;\r\n  if( !$ ) return; // content is not html\r\n\r\n  // extract information from page body\r\n  var wikipedia = {\r\n    uri: res.uri,\r\n    heading: $('h1.firstHeading').text().trim(),\r\n    body: $('div#mw-content-text p').text().trim()\r\n  };\r\n\r\n  console.log( wikipedia );\r\n\r\n});\r\n\r\nspider.queue.add( 'http://en.wikipedia.org/wiki/Huntsman_spider' );\r\nspider.start();\r\n```\r\n\r\n### Example Output\r\n\r\n```bash\r\npeter@edgy:/tmp$ node examples/html.js \r\n{\r\n  \"uri\": \"http://en.wikipedia.org/wiki/Wikipedia:Recent_additions\",\r\n  \"heading\": \"Wikipedia:Recent additions\",\r\n  \"body\": \"This is a selection of recently created new articles and greatly expanded former stub articles on Wikipedia that were featured on the Main Page as part of Did you know? You can submit new pages for consideration. (Archives are grouped by month of Main page appearance.)Tip: To find which archive contains the fact that appeared on Did You Know?, return to the article and click \\\"What links here\\\" to the left of the article. Then, in the dropdown menu provided for namespace, choose Wikipedia and click \\\"Go\\\". When you find \\\"Wikipedia:Recent additions\\\" and a number, click it and search for the article name.\\n\\nCurrent archive\"\r\n}\r\n\r\n... etc\r\n```\r\n\r\nMore examples are available in the [/examples](https://github.com/missinglink/huntsman/tree/master/examples \"Title\") directory\r\n\r\n---\r\n\r\n## How it works\r\n\r\nHuntsman takes one or more 'seed' urls with the `spider.queue.add()` method.\r\n\r\nOnce the process is kicked off with `spider.start()`, it will take care of extracting links from the page and following only the pages we want.\r\n\r\nTo define which pages are crawled use the `spider.on()` function with a string or regular expression.\r\n\r\nEach page will only be crawled once. If multiple regular expressions match the uri, they will all be called.\r\n\r\n**Page URLs which do not match an `on` condition will never be crawled**\r\n\r\n---\r\n\r\n## Configuration\r\n\r\nThe spider has default settings, you can override them by passing a settings object when you create a spider.\r\n\r\n```javascript\r\n// use default settings\r\nvar huntsman = require('huntsman');\r\nvar spider = huntsman.spider();\r\n```\r\n\r\n```javascript\r\n// override default settings\r\nvar huntsman = require('huntsman');\r\nvar spider = huntsman.spider({\r\n  throttle: 10, // maximum requests per second\r\n  timeout: 5000 // maximum gap of inactivity before exiting (in milliseconds)\r\n});\r\n```\r\n\r\n---\r\n\r\n## Crawling a site\r\n\r\nHow you configure your spider will vary from site to site, generally you will only be looking for for pages with a specific url format.\r\n\r\n### Scrape product information from amazon\r\n\r\nIn this example we can see that amazon product uris all seem to share the format `'/gp/product/'`.\r\n\r\nAfter queueing the seed uri `http://www.amazon.co.uk/` huntsman will follow all the product pages it finds recursively.\r\n\r\n```javascript\r\n/** Example of scraping products from the amazon website **/\r\n\r\nvar huntsman = require('huntsman');\r\nvar spider = huntsman.spider();\r\n\r\nspider.extensions = [\r\n  huntsman.extension( 'recurse' ), // load recurse extension & follow anchor links\r\n  huntsman.extension( 'cheerio' ) // load cheerio extension\r\n];\r\n\r\n// target only product uris\r\nspider.on( '/gp/product/', function ( err, res ){\r\n\r\n  if( !res.extension.cheerio ) return; // content is not html\r\n  var $ = res.extension.cheerio;\r\n\r\n  // extract product information\r\n  var product = {\r\n    uri: res.uri,\r\n    heading: $('h1.parseasinTitle').text().trim(),\r\n    image: $('img#main-image').attr('src'),\r\n    description: $('#productDescription').text().trim().substr( 0, 50 )\r\n  };\r\n\r\n  console.log( product );\r\n\r\n});\r\n\r\nspider.queue.add( 'http://www.amazon.co.uk/' );\r\nspider.start();\r\n```\r\n\r\n### Find pets for sale on cragslist in london \r\n\r\nMore complex crawls may require you to specify hub pages to follow before you can get to the content you really want. You can add an `on` event without a callback & huntsman will still follow and extract links from it.\r\n\r\n```javascript\r\n/** Example of scraping information about pets for sale on cragslist in london **/\r\n\r\nvar huntsman = require('huntsman');\r\nvar spider = huntsman.spider({\r\n  throttle: 2\r\n});\r\n\r\nspider.extensions = [\r\n  huntsman.extension( 'recurse' ), // load recurse extension & follow anchor links\r\n  huntsman.extension( 'cheerio' ), // load cheerio extension\r\n  huntsman.extension( 'stats' ) // load stats extension\r\n];\r\n\r\n// target only pet uris\r\nspider.on( /\\/pet\\/(\\w+)\\.html$/, function ( err, res ){\r\n\r\n  if( !res.extension.cheerio ) return; // content is not html\r\n  var $ = res.extension.cheerio;\r\n\r\n  // extract listing information\r\n  var listing = {\r\n    heading: $('h2.postingtitle').text().trim(),\r\n    uri: res.uri,\r\n    image: $('img#iwi').attr('src'),\r\n    description: $('#postingbody').text().trim().substr( 0, 50 )\r\n  };\r\n\r\n  console.log( listing );\r\n\r\n});\r\n\r\n// hub pages\r\nspider.on( /http:\\/\\/london\\.craigslist\\.co\\.uk$/ );\r\nspider.on( /\\/pet$/ );\r\n\r\nspider.queue.add( 'http://www.craigslist.org/about/sites' );\r\nspider.start();\r\n```\r\n\r\n---\r\n\r\n## Extensions\r\n\r\nExtensions have default settings, you can override them by passing an optional second argument when the extension is loaded.\r\n\r\n```javascript\r\n// loading an extension\r\nspider.extensions = [\r\n  huntsman.extension( 'extension_name', options )\r\n];\r\n```\r\n\r\n### recurse\r\n\r\nThis extension extracts links from html pages and then adds them to the queue.\r\n\r\nThe default patterns only target anchor tags which use the http protocol, you can change any of the default patterns by declaring them when the extension is loaded.\r\n\r\n```javascript\r\n// default patterns\r\nhuntsman.extension( 'recurse', {\r\n  pattern: {\r\n    search: /a([^>]+)href\\s?=\\s?['\"]([^\"'#]+)/gi,\r\n    refine: /['\"]([^\"'#]+)$/,\r\n    filter: /^https?:\\/\\//\r\n  }\r\n})\r\n```\r\n\r\n- `search` must be a `global` regexp and is used to target the links we want to extract.\r\n- `refine` is a regexp used to extract the bits we want from the `search` regex matches.\r\n- `filter` is a regexp that must match or links are discarded.\r\n\r\n\r\n```javascript\r\n// extract both anchor tags and script tags\r\nhuntsman.extension( 'recurse', {\r\n  pattern: {\r\n    search: /(a([^>]+)href|script([^>]+)src)\\s?=\\s?['\"]([^\"'#]+)/gi, // anchor or script tags\r\n  }\r\n})\r\n```\r\n\r\n```javascript\r\n// avoid some file extensions\r\nhuntsman.extension( 'recurse', {\r\n  pattern: {\r\n    filter: /^https?:\\/\\/.*(?!\\.(pdf|png|jpg|gif|zip))....$/, // regex lookahead\r\n  }\r\n})\r\n```\r\n\r\n```javascript\r\n// stay on one domain\r\nhuntsman.extension( 'recurse', {\r\n  pattern: {\r\n    filter: /^https?:\\/\\/www.example.com/, // uris must be prefixed with this domain\r\n  }\r\n})\r\n```\r\n\r\nBy default `recurse` converts relative urls to absolute urls and strips fragment identifiers and trailing slashes.\r\n\r\nIf you need even more control you can override the `resolver` & `normaliser` functions to modify these behaviours.\r\n\r\n### cheerio\r\n\r\nThis extension parses html and provides jquery-style selectors & functions.\r\n\r\n```javascript\r\n// default settings\r\nhuntsman.extension( 'cheerio', { lowerCaseTags: true } )\r\n```\r\n\r\nThe `res.extension.cheerio` function is available in your `on` callbacks when the response body is HTML.\r\n\r\n```javascript\r\nspider.on( 'example.com', function ( err, res ){\r\n\r\n  // use jquery-style selectors & functions\r\n  var $ = res.extension.cheerio;\r\n  if( !$ ) return; // content is not html\r\n\r\n  console.log( res.uri, $('h1').text().trim() );\r\n\r\n});\r\n```\r\n\r\n`cheerio` reference: https://github.com/MatthewMueller/cheerio\r\n\r\n### json\r\n\r\nThis extension parses the response body with `JSON.parse()`.\r\n\r\n```javascript\r\n// enable json\r\nhuntsman.extension( 'json' )\r\n```\r\n\r\nThe `res.extension.json` function is available in your `on` callbacks when the response body is json.\r\n\r\n```javascript\r\nspider.on( 'example.com', function ( err, res ){\r\n\r\n  var json = res.extension.json;\r\n  if( !json ) return; // content is not json\r\n\r\n  console.log( res.uri, json );\r\n\r\n});\r\n```\r\n\r\n### links\r\n\r\nThis extension extracts links from html pages and returns the result.\r\n\r\nIt exposes the same functionality that the `recurse` extension uses to extract links.\r\n\r\n```javascript\r\n// enable extension\r\nhuntsman.extension( 'links' )\r\n```\r\n\r\nThe `res.extension.links` function is available in your `on` callbacks when the response body is a string.\r\n\r\n```javascript\r\nspider.on( 'example.com', function ( err, res ){\r\n\r\n  if( !res.extension.links ) return; // content is not a string\r\n\r\n  // extract all image tags from body\r\n  var images = res.extension.links({\r\n    pattern: {\r\n      search: /(img([^>]+)src)\\s?=\\s?['\"]([^\"'#]+)/gi, // extract img tags\r\n      filter: /\\.jpg|\\.gif|\\.png/i // filter file types\r\n    }\r\n  });\r\n\r\n  console.log( images );\r\n\r\n});\r\n```\r\n\r\n### stats\r\n\r\nThis extension displays statistics about pages crawled, error counts etc.\r\n\r\n```javascript\r\n// default settings\r\nhuntsman.extension( 'stats', { tail: false } )\r\n```\r\n\r\n---\r\n\r\n## Custom queues and response storage adapters\r\n\r\nI'm currently working on being able to persist the job queue via something like redis and potentially caching http responses in mongo with a TTL.\r\n\r\nIf you live life on the wild side, these adapters can be configured when you create a spider.\r\n\r\nPull requests welcome.\r\n\r\n---\r\n\r\n## Build Status\r\n\r\n[![Build Status](https://travis-ci.org/missinglink/huntsman.png?branch=master)](https://travis-ci.org/missinglink/huntsman)","google":"UA-42558273-1","note":"Don't delete this file! It's used internally to help with page regeneration."}